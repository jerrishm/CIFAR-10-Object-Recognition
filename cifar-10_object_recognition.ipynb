{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "CNN_Final.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9jn0jPMTpgg",
        "colab_type": "text"
      },
      "source": [
        "# Transfer Learning and Visualization (CNN's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrIENzDTpgk",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "load the appropriate libraries needed for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6j3bLYtTpgm",
        "colab_type": "code",
        "outputId": "495f7277-1c3c-4a43-c5fa-23c3824b3749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMNx_rB6Tpgt",
        "colab_type": "text"
      },
      "source": [
        "#### Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xthqQ6GTpgu",
        "colab_type": "text"
      },
      "source": [
        "load ResNet50 with just the convolutional layers and not the dense layers so we can train our new dataset on the new dense layers that we create"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHgnB7WyTpgw",
        "colab_type": "code",
        "outputId": "98882a61-dea8-4153-a039-0743c0472b16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pq2-m-8iTpg1",
        "colab_type": "text"
      },
      "source": [
        "The ResNet architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "28uhwZ5aTpg2",
        "colab_type": "code",
        "outputId": "3bcf28c6-8765-48e2-e72c-de9f7b211009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 206, 206, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 100, 100, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 100, 100, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 100, 100, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 102, 102, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 50, 50, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 50, 50, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 50, 50, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 50, 50, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 50, 50, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 50, 50, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 50, 50, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 50, 50, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 50, 50, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 50, 50, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 50, 50, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 50, 50, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 50, 50, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 50, 50, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 50, 50, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 50, 50, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 50, 50, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 25, 25, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 25, 25, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 25, 25, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 25, 25, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 25, 25, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 25, 25, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 25, 25, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 25, 25, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 25, 25, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 25, 25, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 25, 25, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 25, 25, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 25, 25, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 25, 25, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 25, 25, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 25, 25, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 25, 25, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 25, 25, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 13, 13, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 13, 13, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 13, 13, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 13, 13, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 13, 13, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 13, 13, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 13, 13, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 13, 13, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 13, 13, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 13, 13, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 13, 13, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 13, 13, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 13, 13, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 13, 13, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 13, 13, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 13, 13, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 13, 13, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 13, 13, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 13, 13, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 13, 13, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 13, 13, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 13, 13, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 13, 13, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 13, 13, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 13, 13, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 13, 13, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ISX_EYcTpg6",
        "colab_type": "text"
      },
      "source": [
        "Let's work with the cifar10 dataset which we can load directly from keras' dataset library. The Cifar10 data description is as follows - \"The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGnkBfPJTpg8",
        "colab_type": "text"
      },
      "source": [
        "*Changed the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7J-hQm8nTpg9",
        "colab_type": "code",
        "outputId": "5db8be7f-1ade-4eba-b49e-c6406f5b9c13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT7gdPBjTphF",
        "colab_type": "text"
      },
      "source": [
        "*Added layers and changed architecture*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBVXEosQTphH",
        "colab_type": "text"
      },
      "source": [
        "*Retrained the model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKZ7lRM8TphI",
        "colab_type": "code",
        "outputId": "d7ce8f39-8cc5-4666-e02b-77aa178dbccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=20, validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 873s 17ms/sample - loss: 0.2411 - acc: 0.9151 - val_loss: 0.1093 - val_acc: 0.9619\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 855s 17ms/sample - loss: 0.1531 - acc: 0.9457 - val_loss: 0.0698 - val_acc: 0.9770\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 854s 17ms/sample - loss: 0.1173 - acc: 0.9604 - val_loss: 0.0521 - val_acc: 0.9835\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 851s 17ms/sample - loss: 0.0940 - acc: 0.9698 - val_loss: 0.0443 - val_acc: 0.9859\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 852s 17ms/sample - loss: 0.0762 - acc: 0.9766 - val_loss: 0.0391 - val_acc: 0.9878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0uspMGzTphM",
        "colab_type": "text"
      },
      "source": [
        "Let's save the model as an h5 file and load it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmycyWETTphO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UyZIDbUTphS",
        "colab_type": "text"
      },
      "source": [
        "Next, let's evaluate our model on the test set. This yields a 98.79% accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VB4Uqih3TphU",
        "colab_type": "code",
        "outputId": "5fb769be-bde5-4171-d168-02b67ebb40b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 41s 4ms/sample - loss: 0.0391 - acc: 0.9878\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.03914608596265316, 0.9877599]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vi-H_iP9Tpha",
        "colab_type": "code",
        "outputId": "1ab458cb-b49d-444a-c950-657f95a442c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) multiple                  0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo multiple                  524288    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  16777344  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch multiple                  512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch multiple                  256       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  650       \n",
            "=================================================================\n",
            "Total params: 40,899,018\n",
            "Trainable params: 40,583,370\n",
            "Non-trainable params: 315,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr4Tni9yTphe",
        "colab_type": "text"
      },
      "source": [
        "#### Visualization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVB9Q9bkTphf",
        "colab_type": "text"
      },
      "source": [
        "The training/validation loss and accuracy visualizations are shown below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zisdfr-iTphg",
        "colab_type": "code",
        "outputId": "2f45ce5f-b1c1-47ec-d373-5db698e2dffa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'bo', label='Training Accuracy', c='orange')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy', c='orange')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7efff139cda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA00AAAEWCAYAAAC61XwxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8P8BVPps14fwR+4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1008x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}